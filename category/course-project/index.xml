<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>course project | Nishant Mishra</title>
    <link>/category/course-project/</link>
      <atom:link href="/category/course-project/index.xml" rel="self" type="application/rss+xml" />
    <description>course project</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2020</copyright><lastBuildDate>Fri, 01 May 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>course project</title>
      <link>/category/course-project/</link>
    </image>
    
    <item>
      <title>Policy Gradient</title>
      <link>/project/policy_gradient/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      <guid>/project/policy_gradient/</guid>
      <description>&lt;p&gt;This project was done as part of my final project submission for 
&lt;a href=&#34;https://www.cs.mcgill.ca/~dprecup/courses/RL/lectures.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;COMP767: Reinforcement Learning&lt;/a&gt;

 course at McGill University&lt;/p&gt;
&lt;p&gt;In the recent years, significant work has been done in the field of Deep Reinforcement
Learning, to solve challenging problems in many diverse domains. One such example,
are Policy gradient algorithms, which are ubiquitous in state-of-the-art continuous control
tasks. Policy gradient methods can be generally divided into two groups: off-policy
gradient methods, such as 
&lt;a href=&#34;https://arxiv.org/abs/1509.02971&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Deterministic Policy Gradients (DDPG)&lt;/a&gt;

, 
&lt;a href=&#34;https://arxiv.org/pdf/1802.09477.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Twin Delayed
Deep Deterministic (TD3)&lt;/a&gt;

, 
&lt;a href=&#34;https://arxiv.org/abs/1801.01290&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Soft Actor Critic (SAC)&lt;/a&gt;

 and on-policy methods, such as

&lt;a href=&#34;https://arxiv.org/abs/1502.05477&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trust Region Policy Optimization (TRPO)&lt;/a&gt;

.&lt;/p&gt;
&lt;p&gt;However, despite these successes on paper, reproducing deep RL results is rarely straightforward. There are many sources of possible instability and variance including extrinsic
factors (such as hyper-parameters, noise-functions used) or intrinsic factors (such as random
seeds, environment properties).&lt;/p&gt;
&lt;p&gt;In this project, we perform two different analysis on these policy gradient methods:
(i) Reproduction and Comparison: We implement a variant of DDPG, based on the original
paper. We then attempt to reproduce the results of DDPG (our implementation) and
TD3 and compare them with the well-established methods of REINFORCE and A2C.
(ii) Hyper-Parameter Tuning: We also, study the effect of various Hyper-Parameters(namely
Network Size, Batch Sizes) on the performance of these methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Incremental Knowledge Graphs</title>
      <link>/project/transe/</link>
      <pubDate>Sun, 15 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/project/transe/</guid>
      <description>&lt;p&gt;This project was directed towards the final course project requirement for 
&lt;a href=&#34;https://www.mcgill.ca/study/2019-2020/courses/comp-550&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;COMP 550: Natural Language Processing&lt;/a&gt;

 course at McGill University.&lt;/p&gt;
&lt;p&gt;Knowledge graphs (KGs) succinctly represent
real-world facts as multi-relational graphs. A
plethora of work exists in embedding the information
in KG to a continuous vector space in
order to obtain new facts and facilitate multiple
down-stream NLP tasks.&lt;/p&gt;
&lt;p&gt;Despite the popularity
of the KG embedding problem, to the
best of our knowledge, we find that no existing
work handles dynamic/evolving knowledge
graphs that incorporates facts about new
entities.&lt;/p&gt;
&lt;p&gt;In this project, we propose this problem
as an incremental learning problem and
propose solutions to obtain representations for
new entities and also update the representations
of old entities that share facts with these
newer entities. The primary motive of this setup is to avoid
relearning the knowledge graph embedding altogether
with the occurrence of every new set
of facts (triplets).&lt;/p&gt;
&lt;p&gt;We build our solutions with

&lt;a href=&#34;https://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TransE(Bordes et al.)&lt;/a&gt;

 as our base KG embedding model and
evaluate the learned embeddings on facts associated
with these new entities.&lt;/p&gt;
&lt;p&gt;To this aim, we formulated
two solutions; the first approach followed a finetuning
based transfer-learning solution, and the
second followed a model-agnostic meta-learning
based approach with Graph Convolutional Networks
(GCN). While our model-specific finetuning
approach fared well, the proposed model independent
approach failed to learn representations for a new entity.&lt;/p&gt;
&lt;p&gt;We used 
&lt;a href=&#34;https://github.com/thunlp/OpenKE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenKE’s&lt;/a&gt;

 implementation for setting our model. For our
task, we made changes to the TransE model, so
that it can learn the representations of the new entities. We employed the 
&lt;a href=&#34;https://www.microsoft.com/en-us/download/details.aspx?id=52312&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FB20K&lt;/a&gt;

 dataset
(
&lt;a href=&#34;http://nlp.csai.tsinghua.edu.cn/~lzy/publications/aaai2016_dkrl.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Xie et al., 2016&lt;/a&gt;

) for our task. In addition to
containing all the entities and relations from the
FB15K dataset, this dataset also contains new entities
which was required for our setup. We evaluate the models for link prediction, which
aims to predict the missing h or t for a relation fact
(h, r, t).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
