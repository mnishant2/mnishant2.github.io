[{"authors":["admin"],"categories":null,"content":" Hey!! I am currently pursuing my Masters at the School of Computer Science at McGill University. I am also working as a Graduate Research Assistant in collaboration with Center for Intelligent Machines and Department of Diagnostic Radiology.\nI completed my Bachelors from Birla Institute of Technology, India  in Electronics and Communication Engineering. Previously, I have worked as a developer in the AI team of a fintech startup in India Signzy. My interests primarily lie in the domain of Deep Learning, specifically its applications to Computer Vision and Natural Language Processing tasks. Currently, I am working on Deep Learning for Digital Histopathology as part of my Master's thesis. It largely involves using sparse approximation based unsupervised instance segmentation in Whole Slide Images and cross modal feature representation learning from both Histopathology and Radiology data for classification tasks.\nIn the past I have worked on a range of projects as part of coursework, internships and job encompassing diverse tasks in areas of Machine Learning like Face Detection, Optical Character Recognition, Information Retrieval from text, Activity Recognition, Image forensics, Speech Recognition among others.\nI intend to pursue a career in AI research, academic or industrial, in order to push the state of the art in this field and solve the contemporary set of real world problems.   ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1597802042,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/nishant-mishra/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nishant-mishra/","section":"authors","summary":"Hey!! I am currently pursuing my Masters at the School of Computer Science at McGill University. I am also working as a Graduate Research Assistant in collaboration with Center for Intelligent Machines and Department of Diagnostic Radiology.","tags":null,"title":"Nishant Mishra","type":"authors"},{"authors":["admin2"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1597802042,"objectID":"ca4549b7186eec7214c27e470e158988","permalink":"/author/nishant-mishra/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nishant-mishra/","section":"authors","summary":"","tags":null,"title":"Nishant Mishra","type":"authors"},{"authors":[],"categories":[],"content":"","date":1598016519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016519,"objectID":"9292e43774e11c9f7cbc975f7c85919c","permalink":"/project/transe/","publishdate":"2020-08-21T09:28:39-04:00","relpermalink":"/project/transe/","section":"project","summary":"","tags":[],"title":"Transe","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016511,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016511,"objectID":"03b56821ec39c07e58dc185732dd17d0","permalink":"/project/charir/","publishdate":"2020-08-21T09:28:31-04:00","relpermalink":"/project/charir/","section":"project","summary":"","tags":[],"title":"CharIR","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016348,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016348,"objectID":"9a067d49836df8e7d7f1a8a570b04d0e","permalink":"/project/policy_gradient/","publishdate":"2020-08-21T09:25:48-04:00","relpermalink":"/project/policy_gradient/","section":"project","summary":"","tags":[],"title":"Policy_gradient","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016253,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016253,"objectID":"0c3ff430fe61cd0572a41a32dc9d94db","permalink":"/project/march-madness/","publishdate":"2020-08-21T09:24:13-04:00","relpermalink":"/project/march-madness/","section":"project","summary":"","tags":[],"title":"March Madness","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016217,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016217,"objectID":"c85051f0976a751798eef9680b451936","permalink":"/project/online_learning/","publishdate":"2020-08-21T09:23:37-04:00","relpermalink":"/project/online_learning/","section":"project","summary":"","tags":[],"title":"Online_learning","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016169,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016169,"objectID":"c527e142281e6d14536a4f6e73abbf68","permalink":"/project/speaker_recognition/","publishdate":"2020-08-21T09:22:49-04:00","relpermalink":"/project/speaker_recognition/","section":"project","summary":"","tags":[],"title":"Speaker_recognition","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016049,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016049,"objectID":"b6b6e6e8a325200162724a5a975cf700","permalink":"/project/cropnet/","publishdate":"2020-08-21T09:20:49-04:00","relpermalink":"/project/cropnet/","section":"project","summary":"","tags":[],"title":"Cropnet","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016015,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016015,"objectID":"2c27cf46762e06a5d720c1bdf91fbb40","permalink":"/project/activity_recognition/","publishdate":"2020-08-21T09:20:15-04:00","relpermalink":"/project/activity_recognition/","section":"project","summary":"","tags":[],"title":"Activity_recognition","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016000,"objectID":"7b94549be334b87867e5c6d36b8845a5","permalink":"/project/ocr_asr/","publishdate":"2020-08-21T09:20:00-04:00","relpermalink":"/project/ocr_asr/","section":"project","summary":"","tags":[],"title":"OCR_ASR","type":"project"},{"authors":["Nishant Mishra"],"categories":["Computer Vision","layout analysis"],"content":"This project involved an automatic highlighter tool for automatic highlighting and extraction of specific form fields from documents for further processing such as Optical Character Recognition, information retrieval from handwritten documents or even to facilitate semi manual digital population of records from forms using a user interface.\nThe tool utilizes document layout detection, classical Computer vision techniques like template matching and mathematical heuristics to create a generalizable automatic highlighting tool using only one sample of the concerned document.\nThe associated repository here is designed for handling a particular bank form and is a command line highlighting tool that can be appropriated/extended for other documents and interfaces.\n","date":1598015887,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598015887,"objectID":"8a54824059eb2a01e2d09c8a3c54be6f","permalink":"/project/highlighter/","publishdate":"2020-08-21T09:18:07-04:00","relpermalink":"/project/highlighter/","section":"project","summary":"A tool to highlight/extract specific form fields from documents using classical Computer Vision and heuristics","tags":["vision","ocr","text extration"],"title":"Highlighter(Auto field detection)","type":"project"},{"authors":["Nishant Mishra","AB Saravanan"],"categories":["Deep Learning"],"content":"","date":1597725241,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597802042,"objectID":"39398fc5cb4903141e4c8ebf3f61553b","permalink":"/project/dory-ocr/","publishdate":"2020-08-18T00:34:01-04:00","relpermalink":"/project/dory-ocr/","section":"project","summary":"We created an Optical Character Recognition Engine specifically for Indian ID cards using LSTM and CTC loss function.","tags":["vision"],"title":"Dory OCR","type":"project"},{"authors":null,"categories":null,"content":"","date":1597622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597802042,"objectID":"fd36605688ef45e10dc233c860158012","permalink":"/cv/","publishdate":"2020-08-17T00:00:00Z","relpermalink":"/cv/","section":"","summary":"List of Projects,Talks and Publications","tags":null,"title":"CV","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1597622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597802042,"objectID":"475f2249a5c02879faf32697c0e89e6e","permalink":"/portfolio/","publishdate":"2020-08-17T00:00:00Z","relpermalink":"/portfolio/","section":"","summary":"List of Projects,Talks and Publications","tags":null,"title":"Portfolio","type":"widget_page"},{"authors":[],"categories":["deep learning","nlp"],"content":"The project at Signzy involved training a generalizable model for information retrieval from OCR output of Indian ID cards. We used both character level embeddings and word level embeddings( ELMO) in a stacked manner for language modelling before passing the concatenated embeddings to a bidirectional Long Short Term Memory neural network with Conditional Random Field modelling on LSTM output ( Huang et al.) for final classification.\nThe model was trained on a large corpus of text OCR outputs obtained from our own proprietary ID cards dataset for extracting non-trivial information such as Names, dates, numbers, addreses from any card. The training was done in a way to ensure the embeddings were also fine tuned. The FlairNLP library was used to create the preprocessing, text embedding, training and postprocessing pipeline and training was performed using pytorch framework. Multiple combinations of embeddings including FlairEmbeddings( Contextualized string embeddings for sequence labelling), BERT, CharacterEmbeddings, ELMO, XLNet were benchmarked before settling on the final pair based on accuracy, compute and efficiency considerations.\nNot only did the model perform admirably well on unseen text from ID types part of training data irrespective of variations in OCR output and image layout, but it generalised well for out of sample ID types too when finetuned with just 1-5 samples of these cards.\nThe idea behind this was to build a generic, flexible information retrieval engine thats pretrained to extract important information from OCR output of all ID cards without specifically being trained on them or having seen them, without any rule based processing, that can be easily finetuned on a very small number of samples of any new card type for optimum performance. This was made into a rest API as a plug and play product for clients to finetune the model on their samples and then use it out of the box to extract information from IDs. The performance was measured using precision and recall figures.\n","date":1558444841,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558444841,"objectID":"f652a66d3c7e33390d39fe1c6bdd2a7c","permalink":"/project/gem/","publishdate":"2019-05-21T09:20:41-04:00","relpermalink":"/project/gem/","section":"project","summary":"Trained a biLSTM model using both word and character level embeddings for information retrieval from text OCR outputs of ID cards","tags":["nlp"],"title":"Generic Extraction Module (G.E.M)","type":"project"},{"authors":["Nishant Mishra","AB Saravanan","Christen Miller"],"categories":["vision","ensemble"],"content":"Many of the vision based applications or APIs meant for information retrieval/data verification such as Text extraction or face recognition need a minimal quality of image for efficient processing and adequate performance. Hence it becomes imperative to implement an Image quality assessment layer before proceeding with further processing. This will ensure smooth applicaton of the vision algorithms, reliable performance and an overall time reduction by ensuring less redundant computations on oor quality images, and prventing multiple requests and passes through the algorithm.\nThis additional filter helps by ensuring only optimal quality images are passed on and poor quality images are screened at the client/user stage itself saving the users time and the server unnecessary processing, ensuring higher throughput and efficiency.\nWe implemented one such pipeline using an ensemble of models that qualitatively analysed images and produced a quantitative measure for image quality that could then be used as a threshold for decision on whether they are sent for downstream processing or the user is notified to repeat the request with better quality images. This quantitative score ensures flexibility for different tasks and different people tailored to their needs.\nThe model detects the blur in an image( BlurNet), brightness of the image(a ResNet-18 model trained for binary classification i.e dark vs bright) and the text readability(based on performance of text detection and OCR algorithms along with other filtering and morphological operations on the image to estimate textual region) and a meta layer performed computation on their individual outputs to provide a final cumulative Image Quality Score.\nThe final meta learner was trained taking the outputs of individual models as input with the average image quality scores assigned to each image by annotators being the output score. The annotation was done by assigning each image to atleast five random users and asking them to score the image on the three parameters i.e Blur, Brightness and readability out of 10 solely on their personal discretion. These scores were then fit into a weighting formula to generate a cumulative score. This final score obtained from all the annotators for each image was averaged to output the final ground truth score for the image.\nThe clients get both the final score as well as outputs from each individual model along with a short description about the image quality based on the score for analysis.\n","date":1548076823,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548076823,"objectID":"ca1dccfb31083acf903d05d61fa19fa3","permalink":"/project/iqa/","publishdate":"2019-01-21T09:20:23-04:00","relpermalink":"/project/iqa/","section":"project","summary":"An ensemble model to quantify image quality to filter poor quality images at the client end to prevent redundant processing","tags":["vision","blur","brightness","text readability"],"title":"IQA","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597802042,"objectID":"3ef1c3ed755398dc4fffccfec12a9a68","permalink":"/misc/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/misc/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]