[{"authors":["admin"],"categories":null,"content":" Hey!! I am currently pursuing my Masters at the School of Computer Science at McGill University. I am also working as a Graduate Research Assistant in collaboration with Center for Intelligent Machines and Department of Diagnostic Radiology.\nI completed my Bachelors from Birla Institute of Technology, India  in Electronics and Communication Engineering. Previously, I have worked as a developer in the AI team of a fintech startup in India Signzy. My interests primarily lie in the domain of Deep Learning, specifically its applications to Computer Vision and Natural Language Processing tasks.\nCurrently, I am working on Deep Learning for Digital Histopathology as part of my Master's thesis. It largely involves using sparse approximation based unsupervised instance segmentation in Whole Slide Images and cross modal feature representation learning from both Histopathology and Radiology data for classification tasks.\nIn the past I have worked on a range of projects as part of coursework, internships and job encompassing diverse tasks in areas of Machine Learning like Face Detection, Optical Character Recognition, Information Retrieval from text, Activity Recognition, Image forensics, Speech Recognition among others.\nI intend to pursue a career in AI research, academic or industrial, in order to push the state of the art in this field and solve the contemporary set of real world problems.   ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1597802042,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/nishant-mishra/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nishant-mishra/","section":"authors","summary":"Hey!! I am currently pursuing my Masters at the School of Computer Science at McGill University. I am also working as a Graduate Research Assistant in collaboration with Center for Intelligent Machines and Department of Diagnostic Radiology.","tags":null,"title":"Nishant Mishra","type":"authors"},{"authors":["admin2"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1597802042,"objectID":"ca4549b7186eec7214c27e470e158988","permalink":"/author/nishant-mishra/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nishant-mishra/","section":"authors","summary":"","tags":null,"title":"Nishant Mishra","type":"authors"},{"authors":[],"categories":[],"content":"","date":1598016511,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016511,"objectID":"03b56821ec39c07e58dc185732dd17d0","permalink":"/project/charir/","publishdate":"2020-08-21T09:28:31-04:00","relpermalink":"/project/charir/","section":"project","summary":"","tags":[],"title":"CharIR","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016253,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016253,"objectID":"0c3ff430fe61cd0572a41a32dc9d94db","permalink":"/project/march-madness/","publishdate":"2020-08-21T09:24:13-04:00","relpermalink":"/project/march-madness/","section":"project","summary":"","tags":[],"title":"March Madness","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016217,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016217,"objectID":"c85051f0976a751798eef9680b451936","permalink":"/project/online_learning/","publishdate":"2020-08-21T09:23:37-04:00","relpermalink":"/project/online_learning/","section":"project","summary":"","tags":[],"title":"Online_learning","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016169,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016169,"objectID":"c527e142281e6d14536a4f6e73abbf68","permalink":"/project/speaker_recognition/","publishdate":"2020-08-21T09:22:49-04:00","relpermalink":"/project/speaker_recognition/","section":"project","summary":"","tags":[],"title":"Speaker_recognition","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016049,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016049,"objectID":"b6b6e6e8a325200162724a5a975cf700","permalink":"/project/cropnet/","publishdate":"2020-08-21T09:20:49-04:00","relpermalink":"/project/cropnet/","section":"project","summary":"","tags":[],"title":"Cropnet","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016015,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016015,"objectID":"2c27cf46762e06a5d720c1bdf91fbb40","permalink":"/project/activity_recognition/","publishdate":"2020-08-21T09:20:15-04:00","relpermalink":"/project/activity_recognition/","section":"project","summary":"","tags":[],"title":"Activity_recognition","type":"project"},{"authors":[],"categories":[],"content":"","date":1598016000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598016000,"objectID":"7b94549be334b87867e5c6d36b8845a5","permalink":"/project/ocr_asr/","publishdate":"2020-08-21T09:20:00-04:00","relpermalink":"/project/ocr_asr/","section":"project","summary":"","tags":[],"title":"OCR_ASR","type":"project"},{"authors":["Nishant Mishra"],"categories":["Computer Vision","layout analysis"],"content":"This project involved an automatic highlighter tool for automatic highlighting and extraction of specific form fields from documents for further processing such as Optical Character Recognition, information retrieval from handwritten documents or even to facilitate semi manual digital population of records from forms using a user interface.\nThe tool utilizes document layout detection, classical Computer vision techniques like template matching and mathematical heuristics to create a generalizable automatic highlighting tool using only one sample of the concerned document.\nThe associated repository here is designed for handling a particular bank form and is a command line highlighting tool that can be appropriated/extended for other documents and interfaces.\n","date":1598015887,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598015887,"objectID":"8a54824059eb2a01e2d09c8a3c54be6f","permalink":"/project/highlighter/","publishdate":"2020-08-21T09:18:07-04:00","relpermalink":"/project/highlighter/","section":"project","summary":"A tool to highlight/extract specific form fields from documents using classical Computer Vision and heuristics","tags":["vision","ocr","text extration"],"title":"Highlighter(Auto field detection)","type":"project"},{"authors":["Nishant Mishra","AB Saravanan"],"categories":["Deep Learning"],"content":"","date":1597725241,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597802042,"objectID":"39398fc5cb4903141e4c8ebf3f61553b","permalink":"/project/dory-ocr/","publishdate":"2020-08-18T00:34:01-04:00","relpermalink":"/project/dory-ocr/","section":"project","summary":"We created an Optical Character Recognition Engine specifically for Indian ID cards using LSTM and CTC loss function.","tags":["vision"],"title":"Dory OCR","type":"project"},{"authors":null,"categories":null,"content":"","date":1597622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597802042,"objectID":"fd36605688ef45e10dc233c860158012","permalink":"/cv/","publishdate":"2020-08-17T00:00:00Z","relpermalink":"/cv/","section":"","summary":"List of Projects,Talks and Publications","tags":null,"title":"CV","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1597622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597802042,"objectID":"475f2249a5c02879faf32697c0e89e6e","permalink":"/portfolio/","publishdate":"2020-08-17T00:00:00Z","relpermalink":"/portfolio/","section":"","summary":"List of Projects,Talks and Publications","tags":null,"title":"Portfolio","type":"widget_page"},{"authors":["Shubham Chopra","Nishant Mishra"],"categories":["Reinforcement Learning","course project"],"content":"This project was done as part of my final project submission for COMP767: Reinforcement Learning course at McGill University\nIn the recent years, significant work has been done in the field of Deep Reinforcement Learning, to solve challenging problems in many diverse domains. One such example, are Policy gradient algorithms, which are ubiquitous in state-of-the-art continuous control tasks. Policy gradient methods can be generally divided into two groups: off-policy gradient methods, such as Deep Deterministic Policy Gradients (DDPG), Twin Delayed Deep Deterministic (TD3), Soft Actor Critic (SAC) and on-policy methods, such as Trust Region Policy Optimization (TRPO).\nHowever, despite these successes on paper, reproducing deep RL results is rarely straightforward. There are many sources of possible instability and variance including extrinsic factors (such as hyper-parameters, noise-functions used) or intrinsic factors (such as random seeds, environment properties).\nIn this project, we perform two different analysis on these policy gradient methods: (i) Reproduction and Comparison: We implement a variant of DDPG, based on the original paper. We then attempt to reproduce the results of DDPG (our implementation) and TD3 and compare them with the well-established methods of REINFORCE and A2C. (ii) Hyper-Parameter Tuning: We also, study the effect of various Hyper-Parameters(namely Network Size, Batch Sizes) on the performance of these methods.\n","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"9a067d49836df8e7d7f1a8a570b04d0e","permalink":"/project/policy_gradient/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/project/policy_gradient/","section":"project","summary":"Reproducibility and Analysis of Deep Policy Gradient methods for Reinforcement Learning Tasks","tags":["RL","Policy Gradients"],"title":"Policy Gradient","type":"project"},{"authors":["Priyesh Vijayan","Ashita Diwan","Nishant Mishra"],"categories":["graph representation learning","nlp","course project"],"content":"This project was directed towards the final course project requirement for COMP 550: Natural Language Processing course at McGill University.\nKnowledge graphs (KGs) succinctly represent real-world facts as multi-relational graphs. A plethora of work exists in embedding the information in KG to a continuous vector space in order to obtain new facts and facilitate multiple down-stream NLP tasks.\nDespite the popularity of the KG embedding problem, to the best of our knowledge, we find that no existing work handles dynamic/evolving knowledge graphs that incorporates facts about new entities.\nIn this project, we propose this problem as an incremental learning problem and propose solutions to obtain representations for new entities and also update the representations of old entities that share facts with these newer entities. The primary motive of this setup is to avoid relearning the knowledge graph embedding altogether with the occurrence of every new set of facts (triplets).\nWe build our solutions with TransE(Bordes et al.) as our base KG embedding model and evaluate the learned embeddings on facts associated with these new entities.\nTo this aim, we formulated two solutions; the first approach followed a finetuning based transfer-learning solution, and the second followed a model-agnostic meta-learning based approach with Graph Convolutional Networks (GCN). While our model-specific finetuning approach fared well, the proposed model independent approach failed to learn representations for a new entity.\nWe used OpenKE’s implementation for setting our model. For our task, we made changes to the TransE model, so that it can learn the representations of the new entities. We employed the FB20K dataset ( Xie et al., 2016) for our task. In addition to containing all the entities and relations from the FB15K dataset, this dataset also contains new entities which was required for our setup. We evaluate the models for link prediction, which aims to predict the missing h or t for a relation fact (h, r, t).\n","date":1576368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576368000,"objectID":"9292e43774e11c9f7cbc975f7c85919c","permalink":"/project/transe/","publishdate":"2019-12-15T00:00:00Z","relpermalink":"/project/transe/","section":"project","summary":"In this project, we propose an incremental learning problem for Knowledge Graphs to obtain representations for new entities and also update the representations of old entities that share facts with these newer entities.","tags":["nlp","graph represeantation learning","GCN","TransE"],"title":"Incremental Knowledge Graphs","type":"project"},{"authors":[],"categories":["deep learning","nlp"],"content":"The project at Signzy involved training a generalizable model for information retrieval from OCR output of Indian ID cards. We used both character level embeddings and word level embeddings( ELMO) in a stacked manner for language modelling before passing the concatenated embeddings to a bidirectional Long Short Term Memory neural network with Conditional Random Field modelling on LSTM output ( Huang et al.) for final classification.\nThe model was trained on a large corpus of text OCR outputs obtained from our own proprietary ID cards dataset for extracting non-trivial information such as Names, dates, numbers, addreses from any card. The training was done in a way to ensure the embeddings were also fine tuned. The FlairNLP library was used to create the preprocessing, text embedding, training and postprocessing pipeline and training was performed using pytorch framework. Multiple combinations of embeddings including FlairEmbeddings( Contextualized string embeddings for sequence labelling), BERT, CharacterEmbeddings, ELMO, XLNet were benchmarked before settling on the final pair based on accuracy, compute and efficiency considerations.\nNot only did the model perform admirably well on unseen text from ID types part of training data irrespective of variations in OCR output and image layout, but it generalised well for out of sample ID types too when finetuned with just 1-5 samples of these cards.\nThe idea behind this was to build a generic, flexible information retrieval engine thats pretrained to extract important information from OCR output of all ID cards without specifically being trained on them or having seen them, without any rule based processing, that can be easily finetuned on a very small number of samples of any new card type for optimum performance. This was made into a rest API as a plug and play product for clients to finetune the model on their samples and then use it out of the box to extract information from IDs. The performance was measured using precision and recall figures.\n","date":1558444841,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558444841,"objectID":"f652a66d3c7e33390d39fe1c6bdd2a7c","permalink":"/project/gem/","publishdate":"2019-05-21T09:20:41-04:00","relpermalink":"/project/gem/","section":"project","summary":"Trained a biLSTM model using both word and character level embeddings for information retrieval from text OCR outputs of ID cards","tags":["nlp"],"title":"Generic Extraction Module (G.E.M)","type":"project"},{"authors":["Nishant Mishra","AB Saravanan","Christen Miller"],"categories":["vision","ensemble"],"content":"Many of the vision based applications or APIs meant for information retrieval/data verification such as Text extraction or face recognition need a minimal quality of image for efficient processing and adequate performance. Hence it becomes imperative to implement an Image quality assessment layer before proceeding with further processing. This will ensure smooth applicaton of the vision algorithms, reliable performance and an overall time reduction by ensuring less redundant computations on oor quality images, and prventing multiple requests and passes through the algorithm.\nThis additional filter helps by ensuring only optimal quality images are passed on and poor quality images are screened at the client/user stage itself saving the users time and the server unnecessary processing, ensuring higher throughput and efficiency.\nWe implemented one such pipeline using an ensemble of models that qualitatively analysed images and produced a quantitative measure for image quality that could then be used as a threshold for decision on whether they are sent for downstream processing or the user is notified to repeat the request with better quality images. This quantitative score ensures flexibility for different tasks and different people tailored to their needs.\nThe model detects the blur in an image( BlurNet), brightness of the image(a ResNet-18 model trained for binary classification i.e dark vs bright) and the text readability(based on performance of text detection and OCR algorithms along with other filtering and morphological operations on the image to estimate textual region) and a meta layer performed computation on their individual outputs to provide a final cumulative Image Quality Score.\nThe final meta learner was trained taking the outputs of individual models as input with the average image quality scores assigned to each image by annotators being the output score. The annotation was done by assigning each image to atleast five random users and asking them to score the image on the three parameters i.e Blur, Brightness and readability out of 10 solely on their personal discretion. These scores were then fit into a weighting formula to generate a cumulative score. This final score obtained from all the annotators for each image was averaged to output the final ground truth score for the image.\nThe clients get both the final score as well as outputs from each individual model along with a short description about the image quality based on the score for analysis.\n","date":1548076823,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548076823,"objectID":"ca1dccfb31083acf903d05d61fa19fa3","permalink":"/project/iqa/","publishdate":"2019-01-21T09:20:23-04:00","relpermalink":"/project/iqa/","section":"project","summary":"An ensemble model to quantify image quality to filter poor quality images at the client end to prevent redundant processing","tags":["vision","blur","brightness","text readability"],"title":"IQA","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597802042,"objectID":"3ef1c3ed755398dc4fffccfec12a9a68","permalink":"/misc/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/misc/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]